{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Assignment 9: Final Project\n",
    "## Computational Methods in Psychology (and Neuroscience)\n",
    "### Psychology 4500/7559 --- Fall 2020\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Objectives\n",
    "\n",
    "Upon completion of this assignment, students will have:\n",
    "\n",
    "1. Described the list generation process in detail\n",
    "2. Described the experiment details\n",
    "3. Visualized processed data\n",
    "4. Performed a statistical analysis to test the hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Assignment\n",
    "\n",
    "Write text (in MarkDown cells) and code (in Code cells) in a Jupyter notebook (after making a copy and renaming it to have your userid in the title --- e.g., A09_Final_Project_mst3k).\n",
    "\n",
    "\n",
    "## Details\n",
    "\n",
    "The goal of the final project is to synthesize material covered in the class and produce part of what would go into an actual scientific publication based on *one* of the experiments we ran in the class. Specifically, you will be writing part of the Methods and Results sections.\n",
    "\n",
    "The basic template is below the code for loading and processing the data. There we outline what each section should include. As always, make sure to label all figures and be sure to refer to the code in the lesson notebooks as a guide for your analyses.\n",
    "\n",
    "Please feel free to reach out to us on Slack if you have any questions along the way.\n",
    "\n",
    "* ***When you are done, save this notebook as HTML (`File -> Download as -> HTML`) and upload it to the matching assignment on UVACollab.***  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## General Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some useful libraries\n",
    "import numpy as np                # numerical analysis linear algebra\n",
    "import pandas as pd               # efficient tables\n",
    "import matplotlib.pyplot as plt   # plotting\n",
    "import plotnine as pn \n",
    "import scipy.stats.distributions as dists     # probability distributions\n",
    "from scipy import stats\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "from smile.log import log2dl\n",
    "\n",
    "from ci_within import ci_within\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Custom SLOG loading function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom function to load slogs\n",
    "def load_all_subj_logs(task_dir, log_file):\n",
    "    # load in a list of all the subj\n",
    "    subjs = [os.path.split(subj_dir)[-1] \n",
    "             for subj_dir in glob(os.path.join(task_dir, 's*'))]\n",
    "    subjs.sort()\n",
    "\n",
    "    # loop over subj and their data\n",
    "    all_dat = []\n",
    "    for subj in subjs:\n",
    "        # set the file\n",
    "        log_path = os.path.join(task_dir, subj, log_file)\n",
    "        #print(log_path)\n",
    "\n",
    "        # load the data\n",
    "        all_dat.extend(log2dl(log_path, subj=subj))\n",
    "\n",
    "    df = pd.DataFrame(all_dat)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Load in all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resp_map_lure</th>\n",
       "      <th>resp_map_target</th>\n",
       "      <th>block_num</th>\n",
       "      <th>trial_num</th>\n",
       "      <th>stim_on_time</th>\n",
       "      <th>stim_on_error</th>\n",
       "      <th>resp</th>\n",
       "      <th>resp_time_time</th>\n",
       "      <th>resp_time_error</th>\n",
       "      <th>rt</th>\n",
       "      <th>...</th>\n",
       "      <th>valence_sd</th>\n",
       "      <th>arousal_mean</th>\n",
       "      <th>arousal_sd</th>\n",
       "      <th>dominance_mean</th>\n",
       "      <th>dominance_sd</th>\n",
       "      <th>word_frequency</th>\n",
       "      <th>novelty</th>\n",
       "      <th>cond</th>\n",
       "      <th>subj</th>\n",
       "      <th>log_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>234.395511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>J</td>\n",
       "      <td>235.284833</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.889323</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5700000000000001</td>\n",
       "      <td>5.3099999999999996</td>\n",
       "      <td>2.23</td>\n",
       "      <td>5.46</td>\n",
       "      <td>2.0499999999999998</td>\n",
       "      <td>3</td>\n",
       "      <td>target</td>\n",
       "      <td>neu</td>\n",
       "      <td>s001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>235.885654</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>237.034670</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>1.149016</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.1200000000000001</td>\n",
       "      <td>1.8300000000000001</td>\n",
       "      <td>5.6600000000000001</td>\n",
       "      <td>1.78</td>\n",
       "      <td>12</td>\n",
       "      <td>lure</td>\n",
       "      <td>neu</td>\n",
       "      <td>s001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>237.616869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>238.767406</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>1.150537</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8200000000000001</td>\n",
       "      <td>5.4500000000000002</td>\n",
       "      <td>2.1499999999999999</td>\n",
       "      <td>4.6399999999999997</td>\n",
       "      <td>2.0699999999999998</td>\n",
       "      <td>16</td>\n",
       "      <td>lure</td>\n",
       "      <td>neu</td>\n",
       "      <td>s001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>239.624933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>240.432295</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.807362</td>\n",
       "      <td>...</td>\n",
       "      <td>1.24</td>\n",
       "      <td>3.9500000000000002</td>\n",
       "      <td>2.5800000000000001</td>\n",
       "      <td>5.3700000000000001</td>\n",
       "      <td>1.6399999999999999</td>\n",
       "      <td>19</td>\n",
       "      <td>lure</td>\n",
       "      <td>neu</td>\n",
       "      <td>s001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>241.432209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>242.545227</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>1.113017</td>\n",
       "      <td>...</td>\n",
       "      <td>2.1600000000000001</td>\n",
       "      <td>3.6800000000000002</td>\n",
       "      <td>2.5699999999999998</td>\n",
       "      <td>5.8300000000000001</td>\n",
       "      <td>1.5</td>\n",
       "      <td>49</td>\n",
       "      <td>lure</td>\n",
       "      <td>neu</td>\n",
       "      <td>s001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  resp_map_lure resp_map_target  block_num  trial_num  stim_on_time  \\\n",
       "0             F               J          0          0    234.395511   \n",
       "1             F               J          0          1    235.885654   \n",
       "2             F               J          0          2    237.616869   \n",
       "3             F               J          0          3    239.624933   \n",
       "4             F               J          0          4    241.432209   \n",
       "\n",
       "   stim_on_error resp  resp_time_time  resp_time_error        rt  ...  \\\n",
       "0            0.0    J      235.284833         0.000180  0.889323  ...   \n",
       "1            0.0    F      237.034670         0.000182  1.149016  ...   \n",
       "2            0.0    F      238.767406         0.000238  1.150537  ...   \n",
       "3            0.0    F      240.432295         0.000182  0.807362  ...   \n",
       "4            0.0    F      242.545227         0.000192  1.113017  ...   \n",
       "\n",
       "           valence_sd        arousal_mean          arousal_sd  \\\n",
       "0  1.5700000000000001  5.3099999999999996                2.23   \n",
       "1                 1.5  4.1200000000000001  1.8300000000000001   \n",
       "2  1.8200000000000001  5.4500000000000002  2.1499999999999999   \n",
       "3                1.24  3.9500000000000002  2.5800000000000001   \n",
       "4  2.1600000000000001  3.6800000000000002  2.5699999999999998   \n",
       "\n",
       "       dominance_mean        dominance_sd word_frequency novelty cond  subj  \\\n",
       "0                5.46  2.0499999999999998              3  target  neu  s001   \n",
       "1  5.6600000000000001                1.78             12    lure  neu  s001   \n",
       "2  4.6399999999999997  2.0699999999999998             16    lure  neu  s001   \n",
       "3  5.3700000000000001  1.6399999999999999             19    lure  neu  s001   \n",
       "4  5.8300000000000001                 1.5             49    lure  neu  s001   \n",
       "\n",
       "  log_num  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data from the word recog task\n",
    "task_dir = os.path.join('..', 'lessons', 'data2', 'Taskapalooza')\n",
    "\n",
    "df_f = load_all_subj_logs(task_dir, 'log_flanker')\n",
    "df_i = load_all_subj_logs(task_dir, 'log_image_test')\n",
    "df_w = load_all_subj_logs(task_dir, 'log_word_test')\n",
    "df_w.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Some data clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it turns out the cond is easier to visualize as pure and mixed\n",
    "def fix_conds(df, type_col):\n",
    "    # loop over the unique subjects\n",
    "    usubj = df.subj.unique()\n",
    "    for s in usubj:\n",
    "        # loop over their blocks\n",
    "        ublocks = df.loc[df['subj']==s, 'block_num'].unique()\n",
    "        for b in ublocks:\n",
    "            # grab the data for that subj and block\n",
    "            dfb = df.loc[(df['subj']==s)&(df['block_num']==b)]\n",
    "            \n",
    "            # get the unique types in that block\n",
    "            uval = dfb[type_col].unique()\n",
    "            if len(uval) > 1:\n",
    "                # it's mixed\n",
    "                df.loc[(df['subj']==s)&(df.block_num==b), 'cond'] = 'mixed'\n",
    "            else:\n",
    "                # it's the pure\n",
    "                df.loc[(df['subj']==s)&(df.block_num==b), 'cond'] = 'pure'\n",
    "\n",
    "# fix the conds in the recog experiments (updated in place)\n",
    "fix_conds(df_i, type_col='in_out')\n",
    "fix_conds(df_w, type_col='valence')\n",
    "\n",
    "# add in log_rt columns\n",
    "df_f['log_rt'] = np.log(df_f['rt'])\n",
    "df_i['log_rt'] = np.log(df_i['rt'])\n",
    "df_w['log_rt'] = np.log(df_w['rt'])\n",
    "\n",
    "# must make correct an int\n",
    "df_f['correct'] = df_f['correct'].astype(np.int)\n",
    "df_i['correct'] = df_i['correct'].astype(np.int)\n",
    "df_w['correct'] = df_w['correct'].astype(np.int)\n",
    "\n",
    "# add in a column for whether they made an 'old' response\n",
    "df_i['old_resp'] = (df_i['resp_map_target'] == df_i['resp']).astype(np.int)\n",
    "df_w['old_resp'] = (df_w['resp_map_target'] == df_w['resp']).astype(np.int)\n",
    "\n",
    "# process some of the valence info\n",
    "df_w['valence_mean'] = df_w['valence_mean'].astype(np.float)\n",
    "df_w['arousal_mean'] = df_w['arousal_mean'].astype(np.float)\n",
    "df_w['dominance_mean'] = df_w['dominance_mean'].astype(np.float)\n",
    "df_w['abs_valence'] = np.abs(df_w['valence_mean'] - 5.0)\n",
    "df_w['abs_arousal'] = np.abs(df_w['arousal_mean'] - 5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Your text and code goes below here\n",
    "\n",
    "*All code above should work without modification.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hypothesis\n",
    "\n",
    "There is an effect of valence (potentially interacting with condition) and correctness on response times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Methods\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## List generation\n",
    "\n",
    "### Objective\n",
    "Read in a pool of stimuli and create lists of dictionaries that can be presented to participants as part of the SMILE experiment below.\n",
    "\n",
    "The stimuli are contained in three seperate CSV files:\n",
    "- [Positive Pool](./pos_pool.csv)\n",
    "- [Negative Pool](./neg_pool.csv)\n",
    "- [Neutral Pool](./neu_pool.csv)\n",
    "\n",
    "\n",
    "The script should read these files in as lists of dictionaries (using `DictReader` imported from the `csv` module). \n",
    "\n",
    "Using these pools, the script should create study lists of trials for two experimental conditions: **pure** or **mixed**. \n",
    "- **pure**\n",
    "    - all trials should have words of the same valence\n",
    "    - should have the same number of positive, negative, and neutral pure lists\n",
    "- **mixed**\n",
    "    - each list should contain an equal number of positive, negative, and neutral words in random order\n",
    "\n",
    "Each trial (or study list item) is represented as a **dictionary** containing all the information necessary to identify the stimulus to be presented, details about that stimulus, and the condition in which to present it. This information will be experiment-specific, as outlined below.\n",
    "\n",
    "Every study list should have a matching test list that includes all the study list items, plus a set of lures that match the valence of the studied words.\n",
    "\n",
    "Each block should contain a **pure** study list and test list pair (stored in a dict) for **each** valence (pos, neg, neu), as well as one **mixed** study list and test list pair (stored as a dict) for a total of **four** dicts. \n",
    "\n",
    "\n",
    "\n",
    "The final output called `blocks` should be a shuffled list of the dicts contained within each of it's blocks. \n",
    "***IMPORTANT: `blocks` should end up as a list of dicts of lists of dicts***\n",
    "\n",
    "Finally, the script should be configurable such that you can specify different numbers of lists and trials, along with other details specific to the experiment you decide to do.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Requirements\n",
    "- Important packages to `import`\n",
    "    - `import random`\n",
    "    - `from csv import DictReader`\n",
    "    - `import copy`\n",
    "- Have the external `csv` files downloaded on the same directory \n",
    "    - [Positive Pool](./pos_pool.csv)\n",
    "    - [Negative Pool](./neg_pool.csv)\n",
    "    - [Neutral Pool](./neu_pool.csv)\n",
    "    \n",
    "### Procedure\n",
    "\n",
    "1. Start by initiializing the configuration variables\n",
    "    - `pos_file` = 'pos_pool.csv'\n",
    "    - `neg_file` = 'neg_pool.csv'\n",
    "    - `neu_file` = 'neu_pool.csv'\n",
    "    - `num_pools` = 3 \n",
    "    - `num_items_pure` = number of items in pure lists (must be evenly divisible by num_pools)\n",
    "    - `num_reps` =  number of repetitions of each block type\n",
    "    -  Verify the following (make sure number of mixed items is valid): \n",
    "        - num_items_mixed = int(num_items_pure / num_pools)\n",
    "        - assert num_items_mixed * num_pools == num_items_pure\n",
    "2. Load in the pools of data \n",
    "3. Shuffle the pools \n",
    "4. Define the `gen_block` function that creates a study/test block from the pools past in\n",
    "    - should take in `pools`, `cond`, and `num_items` as input\n",
    "    - \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Read in stimulus pools from an external file\n",
    "- Randomly generate study and test lists to be used in future experiments\n",
    "- Output a list of dicts called `blocks`: \n",
    "    - Each dict within `blocks` contains two elements a `study_list` and a `test_list`\n",
    "    - `study_list` \n",
    "        - should be a list comprised of dicts containing the relvant information of a particular stimuli:\n",
    "            - `stimulus`\n",
    "            - `valence`\n",
    "            - `novelty`\n",
    "            - `cond`\n",
    "            - **Any other relevant information you would like to include**\n",
    "        - should have a size that is configurable \n",
    "    - `test_list`\n",
    "        - should contain all the same items as the associated `study_list`\n",
    "        - should additionally contain the same number of random `LURES` \n",
    "        - should have a total size that is double that of the `study_list`\n",
    "- ***`blocks` should end up as a list of dicts of lists of dicts **\n",
    "\n",
    "## SMILE Experiment Details\n",
    "\n",
    "*Provide enough detail so that someone could implement the experiment presentation and response collection, including all timing information and how the blocks were structured and presented.*\n",
    "\n",
    "### Objective\n",
    "Utilize the lists generated by code from the list generation method above to create an experiment for collecting data. For this Recognition Memory Test, participants will study a list of items one at a time, and then, after a short delay, be tested for their memory of those items. \n",
    "\n",
    "The main objectives of this experiment are the following:\n",
    "- Present an instruction screen to the participant that explains the tasks\n",
    "- Loop over the blocks of study--test lists. Each block has the following structure:\n",
    "    - Wait for the participant to press a key to start the block\n",
    "    - Loop over the study list presenting all the study items, one at a time; Each study item is presented like so:\n",
    "        - Present the item for a specified duration (this should be a configuration variable at the top of your code)\n",
    "        - Wait an inter-stimulus duration plus some amount of jitter (these, too, should be config variables)\n",
    "        - Log the stimulus information, including when it appeared on the screen\n",
    "    - Wait for a delay \n",
    "    - Loop over the test list presenting all the test items, one at a time; Each test item is presented like so:\n",
    "        - Present the item on the screen (with its Label) **until the participant makes a keyboard response of either the key you have selected to indicate the item is \"old\" or the key that indicates the item is \"new\"**\n",
    "        - Log the stimulus information, including when the stimulus appeared on the screen, when the participant made their response, and what response they made\n",
    "- Optional: Present an exit screen to the participant with a fun message!\n",
    "\n",
    "In the test phase of each block, participants will see the study items again, along with an equal number of new items, and for each item they must specify whether the item is an old target item (i.e., one that was on the study list) or a new lure item.\n",
    "\n",
    "\n",
    "\n",
    "### Requirements\n",
    "- Important packages to `import`\n",
    "    - `from smile.common import * `\n",
    "    - `from smile.scale import scale as s`\n",
    "    - `from smile.startup import InputSubject`\n",
    "\n",
    "\n",
    "### Procedure\n",
    "1. Start by initializing the configuration variables (including the listgen variables)\n",
    "    - Important variables include (replace empty or 0 variables with your desired configuration): \n",
    "        - `font_size = 0`\n",
    "        - `resp_keys = ['', '']` ***these are your keys to indicate if the item is \"old\" or if the item is \"new\"***\n",
    "        - `resp_map = {'': '', '': ''}`***this is used to associate the two keys chosen for `resp_keys` with \"old\" or \"new\"***\n",
    "        - `ISI_dur = 0`\n",
    "        - `ISI_jitter = 0` \n",
    "        - `LOC_X_jitter = 0`\n",
    "        - `LOC_Y_jitter = 0`\n",
    "        - `inst_font_size = 0 `\n",
    "        - `stim_time = 0`\n",
    "        - `inst_text = \"\"`\n",
    "        - `study_text = \"\"`\n",
    "        - `test_text = \"\"`\n",
    "        - `blocks` ***this should be created using the list_gen method above***\n",
    "2. Create your subroutines for `Instruct`, `Trial` and `Study`\n",
    "     - `Instruct` \n",
    "         - should use `inst_text` to render the instructions on the screen\n",
    "         - should wait for user input to continue\n",
    "     - `Trial` (This is an individual test item within the test list)\n",
    "         - should take in a `block_num`, `trial_num` and `cur_trial`\n",
    "         - should present the stimulus on the screen \n",
    "         - should wait for a response using the selected `resp_keys` from the participant (no timeout) \n",
    "         - should collect and log relevant data from the participant's response\n",
    "     - `Study` (This is an individual study item within the test list)\n",
    "         - should take in a `block_num`, `trial_num` and `cur_trial`\n",
    "         - should present the stimulus on the screen\n",
    "         - should wait the `ISI_dur` with `ISI_jitter`\n",
    "         - should log relevant data based on the stimulus\n",
    "3. Run Subroutines \n",
    "    1. Take subject id information using `InputSubject`\n",
    "    2. Use `Instruct` to present the instructions to the participant\n",
    "    3. `Wait` ***could use a configured amount or input 0.5 as default***\n",
    "    4. Loop over `blocks`; For each block:\n",
    "        1. Take user input to make sure they are ready to start the block\n",
    "        2. Present them with the `study_text` and wait for user input to make sure they are ready to begin the study portion of the block\n",
    "        3. Loop over the current block's study list using the `Study` subroutine\n",
    "        4. Wait the `ISI_dur` with `ISI_jitter`\n",
    "        5. Loop over the current block's study list using the `Trial` subroutine\n",
    "    4. Optional: Present an exit screen to the participant with a fun message!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Results\n",
    "\n",
    "*In this section, state a specific question, then define your dependent and independent variables that will help you answer that question. As stated above, your question must give rise to an analysis that is not identical to one we performed in class (i.e., you must do more than copy and paste code with zero changes. That said, the analysis can match those from the class quite closely.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data processing and visualization\n",
    "\n",
    "*With the lessons as a guide, process your data to create the necessary data frame to plot the visualization associated with the question stated above. Then plot those data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cond</th>\n",
       "      <th>correct</th>\n",
       "      <th>valence</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>sem</th>\n",
       "      <th>ci</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mixed</td>\n",
       "      <td>0</td>\n",
       "      <td>neg</td>\n",
       "      <td>0.012475</td>\n",
       "      <td>0.443925</td>\n",
       "      <td>0.028304</td>\n",
       "      <td>0.055749</td>\n",
       "      <td>246.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mixed</td>\n",
       "      <td>0</td>\n",
       "      <td>neu</td>\n",
       "      <td>-0.090631</td>\n",
       "      <td>0.428271</td>\n",
       "      <td>0.027645</td>\n",
       "      <td>0.054459</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mixed</td>\n",
       "      <td>0</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.014127</td>\n",
       "      <td>0.467800</td>\n",
       "      <td>0.027565</td>\n",
       "      <td>0.054256</td>\n",
       "      <td>288.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mixed</td>\n",
       "      <td>1</td>\n",
       "      <td>neg</td>\n",
       "      <td>-0.200708</td>\n",
       "      <td>0.374247</td>\n",
       "      <td>0.010688</td>\n",
       "      <td>0.020970</td>\n",
       "      <td>1226.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mixed</td>\n",
       "      <td>1</td>\n",
       "      <td>neu</td>\n",
       "      <td>-0.224007</td>\n",
       "      <td>0.345982</td>\n",
       "      <td>0.009857</td>\n",
       "      <td>0.019339</td>\n",
       "      <td>1232.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mixed</td>\n",
       "      <td>1</td>\n",
       "      <td>pos</td>\n",
       "      <td>-0.180464</td>\n",
       "      <td>0.355232</td>\n",
       "      <td>0.010324</td>\n",
       "      <td>0.020255</td>\n",
       "      <td>1184.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pure</td>\n",
       "      <td>0</td>\n",
       "      <td>neg</td>\n",
       "      <td>-0.049468</td>\n",
       "      <td>0.416569</td>\n",
       "      <td>0.021512</td>\n",
       "      <td>0.042299</td>\n",
       "      <td>375.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pure</td>\n",
       "      <td>0</td>\n",
       "      <td>neu</td>\n",
       "      <td>-0.011461</td>\n",
       "      <td>0.506350</td>\n",
       "      <td>0.026113</td>\n",
       "      <td>0.051346</td>\n",
       "      <td>376.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pure</td>\n",
       "      <td>0</td>\n",
       "      <td>pos</td>\n",
       "      <td>-0.082128</td>\n",
       "      <td>0.445896</td>\n",
       "      <td>0.022295</td>\n",
       "      <td>0.043830</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pure</td>\n",
       "      <td>1</td>\n",
       "      <td>neg</td>\n",
       "      <td>-0.215593</td>\n",
       "      <td>0.384846</td>\n",
       "      <td>0.008989</td>\n",
       "      <td>0.017630</td>\n",
       "      <td>1833.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pure</td>\n",
       "      <td>1</td>\n",
       "      <td>neu</td>\n",
       "      <td>-0.219150</td>\n",
       "      <td>0.357422</td>\n",
       "      <td>0.008351</td>\n",
       "      <td>0.016378</td>\n",
       "      <td>1832.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pure</td>\n",
       "      <td>1</td>\n",
       "      <td>pos</td>\n",
       "      <td>-0.189707</td>\n",
       "      <td>0.375984</td>\n",
       "      <td>0.008842</td>\n",
       "      <td>0.017342</td>\n",
       "      <td>1808.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cond  correct valence      mean       std       sem        ci     len\n",
       "0   mixed        0     neg  0.012475  0.443925  0.028304  0.055749   246.0\n",
       "1   mixed        0     neu -0.090631  0.428271  0.027645  0.054459   240.0\n",
       "2   mixed        0     pos  0.014127  0.467800  0.027565  0.054256   288.0\n",
       "3   mixed        1     neg -0.200708  0.374247  0.010688  0.020970  1226.0\n",
       "4   mixed        1     neu -0.224007  0.345982  0.009857  0.019339  1232.0\n",
       "5   mixed        1     pos -0.180464  0.355232  0.010324  0.020255  1184.0\n",
       "6    pure        0     neg -0.049468  0.416569  0.021512  0.042299   375.0\n",
       "7    pure        0     neu -0.011461  0.506350  0.026113  0.051346   376.0\n",
       "8    pure        0     pos -0.082128  0.445896  0.022295  0.043830   400.0\n",
       "9    pure        1     neg -0.215593  0.384846  0.008989  0.017630  1833.0\n",
       "10   pure        1     neu -0.219150  0.357422  0.008351  0.016378  1832.0\n",
       "11   pure        1     pos -0.189707  0.375984  0.008842  0.017342  1808.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code for data processing and visualization\n",
    "\n",
    "# get the error corrected by condition and whether they answered correctly\n",
    "res = ci_within(df_w,  \n",
    "                indexvar='subj',       # column that identifies a subject\n",
    "                withinvars=['cond', 'correct', 'valence'],     # list of columns for grouping within subject\n",
    "                measvar='log_rt')        # dependent variable averaging over\n",
    "\n",
    "res = res.reset_index()\n",
    "res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ggplot: (7012083129)>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = (pn.ggplot(res, pn.aes('cond', 'mean', fill='valence'))\n",
    "     + pn.geom_errorbar(pn.aes(ymin='mean-ci', ymax='mean+ci', width=0.2), \n",
    "                        position=pn.position_dodge(.7))\n",
    "     + pn.geom_point(position=pn.position_dodge(.7), size=4)\n",
    "     + pn.facet_wrap('~ correct')\n",
    "     + pn.labs(title=\"Plot of Log_rt by valence across correctness\", x=\"Condition\", y = \"P(log_rt)\", fill='Valence')\n",
    "    )\n",
    "p"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "*Put text here describing what is in your plot like a detailed figure caption.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Statistical test and interpretation\n",
    "\n",
    "*Perform a statistical test to support your conclusions with regard to your question outlined above. This can be with either statsmodels or with bambi.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subj</th>\n",
       "      <th>cond</th>\n",
       "      <th>valence</th>\n",
       "      <th>correct</th>\n",
       "      <th>log_rt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s001</td>\n",
       "      <td>mixed</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.167138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s001</td>\n",
       "      <td>mixed</td>\n",
       "      <td>neg</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.217212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s001</td>\n",
       "      <td>mixed</td>\n",
       "      <td>neu</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.109757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s001</td>\n",
       "      <td>mixed</td>\n",
       "      <td>neu</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.215241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s001</td>\n",
       "      <td>mixed</td>\n",
       "      <td>pos</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>s023</td>\n",
       "      <td>pure</td>\n",
       "      <td>neg</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.284881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>s023</td>\n",
       "      <td>pure</td>\n",
       "      <td>neu</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.249797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>s023</td>\n",
       "      <td>pure</td>\n",
       "      <td>neu</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.347838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>s023</td>\n",
       "      <td>pure</td>\n",
       "      <td>pos</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.357336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>s023</td>\n",
       "      <td>pure</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.447838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>276 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subj   cond valence  correct    log_rt\n",
       "0    s001  mixed     neg        0  0.167138\n",
       "1    s001  mixed     neg        1 -0.217212\n",
       "2    s001  mixed     neu        0 -0.109757\n",
       "3    s001  mixed     neu        1 -0.215241\n",
       "4    s001  mixed     pos        0  0.166381\n",
       "..    ...    ...     ...      ...       ...\n",
       "271  s023   pure     neg        1 -0.284881\n",
       "272  s023   pure     neu        0 -0.249797\n",
       "273  s023   pure     neu        1 -0.347838\n",
       "274  s023   pure     pos        0 -0.357336\n",
       "275  s023   pure     pos        1 -0.447838\n",
       "\n",
       "[276 rows x 5 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code for statistical test (can be either with statsmodels or bambi)\n",
    "\n",
    "# use the agg method to get the means\n",
    "perf = df_w.groupby(['subj', 'cond', 'valence', 'correct'])['log_rt'].mean()\n",
    "perf = perf.reset_index()\n",
    "perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>log_rt</td>      <th>  R-squared:         </th> <td>   0.144</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   4.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 02 Dec 2020</td> <th>  Prob (F-statistic):</th> <td>1.70e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:59:04</td>     <th>  Log-Likelihood:    </th> <td> -52.458</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   276</td>      <th>  AIC:               </th> <td>   128.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   264</td>      <th>  BIC:               </th> <td>   172.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    11</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                   <td></td>                      <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                           <td>    0.0358</td> <td>    0.062</td> <td>    0.574</td> <td> 0.566</td> <td>   -0.087</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cond[T.pure]</th>                        <td>   -0.0377</td> <td>    0.088</td> <td>   -0.427</td> <td> 0.670</td> <td>   -0.211</td> <td>    0.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>valence[T.neu]</th>                      <td>   -0.0979</td> <td>    0.088</td> <td>   -1.110</td> <td> 0.268</td> <td>   -0.272</td> <td>    0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>valence[T.pos]</th>                      <td>    0.0480</td> <td>    0.088</td> <td>    0.544</td> <td> 0.587</td> <td>   -0.126</td> <td>    0.222</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cond[T.pure]:valence[T.neu]</th>         <td>    0.1971</td> <td>    0.125</td> <td>    1.580</td> <td> 0.115</td> <td>   -0.049</td> <td>    0.443</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cond[T.pure]:valence[T.pos]</th>         <td>   -0.0671</td> <td>    0.125</td> <td>   -0.538</td> <td> 0.591</td> <td>   -0.313</td> <td>    0.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>correct</th>                             <td>   -0.2348</td> <td>    0.088</td> <td>   -2.661</td> <td> 0.008</td> <td>   -0.409</td> <td>   -0.061</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cond[T.pure]:correct</th>                <td>    0.0233</td> <td>    0.125</td> <td>    0.186</td> <td> 0.852</td> <td>   -0.222</td> <td>    0.269</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>valence[T.neu]:correct</th>              <td>    0.0741</td> <td>    0.125</td> <td>    0.594</td> <td> 0.553</td> <td>   -0.172</td> <td>    0.320</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>valence[T.pos]:correct</th>              <td>   -0.0286</td> <td>    0.125</td> <td>   -0.229</td> <td> 0.819</td> <td>   -0.274</td> <td>    0.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cond[T.pure]:valence[T.neu]:correct</th> <td>   -0.1750</td> <td>    0.176</td> <td>   -0.992</td> <td> 0.322</td> <td>   -0.522</td> <td>    0.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cond[T.pure]:valence[T.pos]:correct</th> <td>    0.0680</td> <td>    0.176</td> <td>    0.385</td> <td> 0.700</td> <td>   -0.279</td> <td>    0.415</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>120.457</td> <th>  Durbin-Watson:     </th> <td>   0.866</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 535.822</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.794</td>  <th>  Prob(JB):          </th> <td>4.44e-117</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.807</td>  <th>  Cond. No.          </th> <td>    25.6</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 log_rt   R-squared:                       0.144\n",
       "Model:                            OLS   Adj. R-squared:                  0.109\n",
       "Method:                 Least Squares   F-statistic:                     4.053\n",
       "Date:                Wed, 02 Dec 2020   Prob (F-statistic):           1.70e-05\n",
       "Time:                        22:59:04   Log-Likelihood:                -52.458\n",
       "No. Observations:                 276   AIC:                             128.9\n",
       "Df Residuals:                     264   BIC:                             172.4\n",
       "Df Model:                          11                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=======================================================================================================\n",
       "                                          coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------------------\n",
       "Intercept                               0.0358      0.062      0.574      0.566      -0.087       0.159\n",
       "cond[T.pure]                           -0.0377      0.088     -0.427      0.670      -0.211       0.136\n",
       "valence[T.neu]                         -0.0979      0.088     -1.110      0.268      -0.272       0.076\n",
       "valence[T.pos]                          0.0480      0.088      0.544      0.587      -0.126       0.222\n",
       "cond[T.pure]:valence[T.neu]             0.1971      0.125      1.580      0.115      -0.049       0.443\n",
       "cond[T.pure]:valence[T.pos]            -0.0671      0.125     -0.538      0.591      -0.313       0.179\n",
       "correct                                -0.2348      0.088     -2.661      0.008      -0.409      -0.061\n",
       "cond[T.pure]:correct                    0.0233      0.125      0.186      0.852      -0.222       0.269\n",
       "valence[T.neu]:correct                  0.0741      0.125      0.594      0.553      -0.172       0.320\n",
       "valence[T.pos]:correct                 -0.0286      0.125     -0.229      0.819      -0.274       0.217\n",
       "cond[T.pure]:valence[T.neu]:correct    -0.1750      0.176     -0.992      0.322      -0.522       0.172\n",
       "cond[T.pure]:valence[T.pos]:correct     0.0680      0.176      0.385      0.700      -0.279       0.415\n",
       "==============================================================================\n",
       "Omnibus:                      120.457   Durbin-Watson:                   0.866\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              535.822\n",
       "Skew:                           1.794   Prob(JB):                    4.44e-117\n",
       "Kurtosis:                       8.807   Cond. No.                         25.6\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build a linear regression of the full model\n",
    "m0 = smf.ols(\"log_rt ~ cond * valence * correct\", perf).fit()\n",
    "m0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>df</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cond</th>\n",
       "      <td>0.000018</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>9.886632e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valence</th>\n",
       "      <td>0.026583</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.148474</td>\n",
       "      <td>8.620946e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cond:valence</th>\n",
       "      <td>0.256683</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.433668</td>\n",
       "      <td>2.402830e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>correct</th>\n",
       "      <td>3.519608</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.316559</td>\n",
       "      <td>1.463755e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cond:correct</th>\n",
       "      <td>0.002658</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.029688</td>\n",
       "      <td>8.633310e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valence:correct</th>\n",
       "      <td>0.004318</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.024119</td>\n",
       "      <td>9.761714e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cond:valence:correct</th>\n",
       "      <td>0.180761</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.009613</td>\n",
       "      <td>3.657622e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>23.633208</td>\n",
       "      <td>264.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         sum_sq     df          F        PR(>F)\n",
       "cond                   0.000018    1.0   0.000202  9.886632e-01\n",
       "valence                0.026583    2.0   0.148474  8.620946e-01\n",
       "cond:valence           0.256683    2.0   1.433668  2.402830e-01\n",
       "correct                3.519608    1.0  39.316559  1.463755e-09\n",
       "cond:correct           0.002658    1.0   0.029688  8.633310e-01\n",
       "valence:correct        0.004318    2.0   0.024119  9.761714e-01\n",
       "cond:valence:correct   0.180761    2.0   1.009613  3.657622e-01\n",
       "Residual              23.633208  264.0        NaN           NaN"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run a type-II repeated measures ANOVA based on the linear model results\n",
    "sm.stats.anova_lm(m0, typ=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Put text here describing the results of your statistical test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Discussion\n",
    "\n",
    "***Graduate students only!!!***\n",
    "\n",
    "*In one to two paragraphs do the following: a) Place the study in the larger literature, summarizing some of the similar work in the field and how this study compares, b) write some analysis of the findings from the study (even if they are null results) and then describe a follow-up study with a new variant of the experiment that you think might help answer further questions on the topic."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "rise": {
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
