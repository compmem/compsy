{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Assignment 9: Final Project\n",
    "## Computational Methods in Psychology (and Neuroscience)\n",
    "### Psychology 4500/7559 --- Fall 2020\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Objectives\n",
    "\n",
    "Upon completion of this assignment, students will have:\n",
    "\n",
    "1. Described the list generation process in detail\n",
    "2. Described the experiment details\n",
    "3. Visualized processed data\n",
    "4. Performed a statistical analysis to test the hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Assignment\n",
    "\n",
    "Write text (in MarkDown cells) and code (in Code cells) in a Jupyter notebook (after making a copy and renaming it to have your userid in the title --- e.g., A09_Final_Project_mst3k).\n",
    "\n",
    "\n",
    "## Details\n",
    "\n",
    "The goal of the final project is to synthesize material covered in the class and produce part of what would go into an actual scientific publication based on *one* of the experiments we ran in the class. Specifically, you will be writing part of the Methods and Results sections.\n",
    "\n",
    "The basic template is below the code for loading and processing the data. There we outline what each section should include. As always, make sure to label all figures and be sure to refer to the code in the lesson notebooks as a guide for your analyses.\n",
    "\n",
    "Please feel free to reach out to us on Slack if you have any questions along the way.\n",
    "\n",
    "* ***When you are done, save this notebook as HTML (`File -> Download as -> HTML`) and upload it to the matching assignment on UVACollab.***  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## General Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some useful libraries\n",
    "import numpy as np                # numerical analysis linear algebra\n",
    "import pandas as pd               # efficient tables\n",
    "import matplotlib.pyplot as plt   # plotting\n",
    "import plotnine as pn \n",
    "import scipy.stats.distributions as dists     # probability distributions\n",
    "from scipy import stats\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "from smile.log import log2dl\n",
    "\n",
    "from ci_within import ci_within\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Custom SLOG loading function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom function to load slogs\n",
    "def load_all_subj_logs(task_dir, log_file):\n",
    "    # load in a list of all the subj\n",
    "    subjs = [os.path.split(subj_dir)[-1] \n",
    "             for subj_dir in glob(os.path.join(task_dir, 's*'))]\n",
    "    subjs.sort()\n",
    "\n",
    "    # loop over subj and their data\n",
    "    all_dat = []\n",
    "    for subj in subjs:\n",
    "        # set the file\n",
    "        log_path = os.path.join(task_dir, subj, log_file)\n",
    "        #print(log_path)\n",
    "\n",
    "        # load the data\n",
    "        all_dat.extend(log2dl(log_path, subj=subj))\n",
    "\n",
    "    df = pd.DataFrame(all_dat)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Load in all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resp_map_lure</th>\n",
       "      <th>resp_map_target</th>\n",
       "      <th>block_num</th>\n",
       "      <th>trial_num</th>\n",
       "      <th>stim_on_time</th>\n",
       "      <th>stim_on_error</th>\n",
       "      <th>resp</th>\n",
       "      <th>resp_time_time</th>\n",
       "      <th>resp_time_error</th>\n",
       "      <th>rt</th>\n",
       "      <th>...</th>\n",
       "      <th>valence_sd</th>\n",
       "      <th>arousal_mean</th>\n",
       "      <th>arousal_sd</th>\n",
       "      <th>dominance_mean</th>\n",
       "      <th>dominance_sd</th>\n",
       "      <th>word_frequency</th>\n",
       "      <th>novelty</th>\n",
       "      <th>cond</th>\n",
       "      <th>subj</th>\n",
       "      <th>log_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>234.395511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>J</td>\n",
       "      <td>235.284833</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.889323</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5700000000000001</td>\n",
       "      <td>5.3099999999999996</td>\n",
       "      <td>2.23</td>\n",
       "      <td>5.46</td>\n",
       "      <td>2.0499999999999998</td>\n",
       "      <td>3</td>\n",
       "      <td>target</td>\n",
       "      <td>neu</td>\n",
       "      <td>s001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>235.885654</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>237.034670</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>1.149016</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.1200000000000001</td>\n",
       "      <td>1.8300000000000001</td>\n",
       "      <td>5.6600000000000001</td>\n",
       "      <td>1.78</td>\n",
       "      <td>12</td>\n",
       "      <td>lure</td>\n",
       "      <td>neu</td>\n",
       "      <td>s001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>237.616869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>238.767406</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>1.150537</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8200000000000001</td>\n",
       "      <td>5.4500000000000002</td>\n",
       "      <td>2.1499999999999999</td>\n",
       "      <td>4.6399999999999997</td>\n",
       "      <td>2.0699999999999998</td>\n",
       "      <td>16</td>\n",
       "      <td>lure</td>\n",
       "      <td>neu</td>\n",
       "      <td>s001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>239.624933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>240.432295</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.807362</td>\n",
       "      <td>...</td>\n",
       "      <td>1.24</td>\n",
       "      <td>3.9500000000000002</td>\n",
       "      <td>2.5800000000000001</td>\n",
       "      <td>5.3700000000000001</td>\n",
       "      <td>1.6399999999999999</td>\n",
       "      <td>19</td>\n",
       "      <td>lure</td>\n",
       "      <td>neu</td>\n",
       "      <td>s001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>241.432209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>242.545227</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>1.113017</td>\n",
       "      <td>...</td>\n",
       "      <td>2.1600000000000001</td>\n",
       "      <td>3.6800000000000002</td>\n",
       "      <td>2.5699999999999998</td>\n",
       "      <td>5.8300000000000001</td>\n",
       "      <td>1.5</td>\n",
       "      <td>49</td>\n",
       "      <td>lure</td>\n",
       "      <td>neu</td>\n",
       "      <td>s001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  resp_map_lure resp_map_target  block_num  trial_num  stim_on_time  \\\n",
       "0             F               J          0          0    234.395511   \n",
       "1             F               J          0          1    235.885654   \n",
       "2             F               J          0          2    237.616869   \n",
       "3             F               J          0          3    239.624933   \n",
       "4             F               J          0          4    241.432209   \n",
       "\n",
       "   stim_on_error resp  resp_time_time  resp_time_error        rt  ...  \\\n",
       "0            0.0    J      235.284833         0.000180  0.889323  ...   \n",
       "1            0.0    F      237.034670         0.000182  1.149016  ...   \n",
       "2            0.0    F      238.767406         0.000238  1.150537  ...   \n",
       "3            0.0    F      240.432295         0.000182  0.807362  ...   \n",
       "4            0.0    F      242.545227         0.000192  1.113017  ...   \n",
       "\n",
       "           valence_sd        arousal_mean          arousal_sd  \\\n",
       "0  1.5700000000000001  5.3099999999999996                2.23   \n",
       "1                 1.5  4.1200000000000001  1.8300000000000001   \n",
       "2  1.8200000000000001  5.4500000000000002  2.1499999999999999   \n",
       "3                1.24  3.9500000000000002  2.5800000000000001   \n",
       "4  2.1600000000000001  3.6800000000000002  2.5699999999999998   \n",
       "\n",
       "       dominance_mean        dominance_sd word_frequency novelty cond  subj  \\\n",
       "0                5.46  2.0499999999999998              3  target  neu  s001   \n",
       "1  5.6600000000000001                1.78             12    lure  neu  s001   \n",
       "2  4.6399999999999997  2.0699999999999998             16    lure  neu  s001   \n",
       "3  5.3700000000000001  1.6399999999999999             19    lure  neu  s001   \n",
       "4  5.8300000000000001                 1.5             49    lure  neu  s001   \n",
       "\n",
       "  log_num  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data from the word recog task\n",
    "task_dir = os.path.join('..', 'lessons', 'data2', 'Taskapalooza')\n",
    "\n",
    "df_f = load_all_subj_logs(task_dir, 'log_flanker')\n",
    "df_i = load_all_subj_logs(task_dir, 'log_image_test')\n",
    "df_w = load_all_subj_logs(task_dir, 'log_word_test')\n",
    "df_w.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Some data clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it turns out the cond is easier to visualize as pure and mixed\n",
    "def fix_conds(df, type_col):\n",
    "    # loop over the unique subjects\n",
    "    usubj = df.subj.unique()\n",
    "    for s in usubj:\n",
    "        # loop over their blocks\n",
    "        ublocks = df.loc[df['subj']==s, 'block_num'].unique()\n",
    "        for b in ublocks:\n",
    "            # grab the data for that subj and block\n",
    "            dfb = df.loc[(df['subj']==s)&(df['block_num']==b)]\n",
    "            \n",
    "            # get the unique types in that block\n",
    "            uval = dfb[type_col].unique()\n",
    "            if len(uval) > 1:\n",
    "                # it's mixed\n",
    "                df.loc[(df['subj']==s)&(df.block_num==b), 'cond'] = 'mixed'\n",
    "            else:\n",
    "                # it's the pure\n",
    "                df.loc[(df['subj']==s)&(df.block_num==b), 'cond'] = 'pure'\n",
    "\n",
    "# fix the conds in the recog experiments (updated in place)\n",
    "fix_conds(df_i, type_col='in_out')\n",
    "fix_conds(df_w, type_col='valence')\n",
    "\n",
    "# add in log_rt columns\n",
    "df_f['log_rt'] = np.log(df_f['rt'])\n",
    "df_i['log_rt'] = np.log(df_i['rt'])\n",
    "df_w['log_rt'] = np.log(df_w['rt'])\n",
    "\n",
    "# must make correct an int\n",
    "df_f['correct'] = df_f['correct'].astype(np.int)\n",
    "df_i['correct'] = df_i['correct'].astype(np.int)\n",
    "df_w['correct'] = df_w['correct'].astype(np.int)\n",
    "\n",
    "# add in a column for whether they made an 'old' response\n",
    "df_i['old_resp'] = (df_i['resp_map_target'] == df_i['resp']).astype(np.int)\n",
    "df_w['old_resp'] = (df_w['resp_map_target'] == df_w['resp']).astype(np.int)\n",
    "\n",
    "# process some of the valence info\n",
    "df_w['valence_mean'] = df_w['valence_mean'].astype(np.float)\n",
    "df_w['arousal_mean'] = df_w['arousal_mean'].astype(np.float)\n",
    "df_w['dominance_mean'] = df_w['dominance_mean'].astype(np.float)\n",
    "df_w['abs_valence'] = np.abs(df_w['valence_mean'] - 5.0)\n",
    "df_w['abs_arousal'] = np.abs(df_w['arousal_mean'] - 5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Your text and code goes below here\n",
    "\n",
    "*All code above should work without modification.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hypothesis\n",
    "\n",
    "There is an effect of valence (potentially interacting with condition) and correctness on response times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Methods\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## List generation\n",
    "\n",
    "### Objective\n",
    "Read in a pool of stimuli and create lists of dictionaries that can be presented to participants as part of the SMILE experiment below.\n",
    "\n",
    "The stimuli are contained in three seperate CSV files:\n",
    "- [Positive Pool](./pos_pool.csv)\n",
    "- [Negative Pool](./neg_pool.csv)\n",
    "- [Neutral Pool](./neu_pool.csv)\n",
    "\n",
    "\n",
    "Read these files in as lists of dictionaries (using `DictReader` imported from the `csv` module). \n",
    "\n",
    "Using these pools, create study lists of trials for two experimental conditions: **pure** or **mixed**. \n",
    "- **pure**\n",
    "    - all trials should have words of the same valence\n",
    "    - should have the same number of positive, negative, and neutral pure lists\n",
    "- **mixed**\n",
    "    - each list should contain an equal number of positive, negative, and neutral words in random order\n",
    "\n",
    "Each trial (or study list item) is represented as a **dictionary** containing all the information necessary to identify the stimulus to be presented, details about that stimulus, and the condition in which to present it. This information will be experiment-specific, as outlined below.\n",
    "\n",
    "Every study list should have a matching test list that includes all the study list items, plus a set of lures that match the valence of the studied words.\n",
    "\n",
    "Each block should contain a **pure** study list and test list pair (stored in a dict) for **each** valence (pos, neg, neu), as well as one **mixed** study list and test list pair (stored as a dict) for a total of **four** dicts. \n",
    "\n",
    "\n",
    "\n",
    "The final output called `blocks` should be a shuffled list of the dicts contained within each of it's blocks. \n",
    "\n",
    "***IMPORTANT: `blocks` should end up as a list of dicts of lists of dicts***\n",
    "\n",
    "Finally, the script should be configurable such that you can specify different numbers of lists and trials, along with other details specific to the experiment you decide to do.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Requirements\n",
    "- Important packages to `import`\n",
    "    - `import random`\n",
    "    - `from csv import DictReader`\n",
    "    - `import copy`\n",
    "- Have the external `csv` files downloaded on the same directory \n",
    "    - [Positive Pool](./pos_pool.csv)\n",
    "    - [Negative Pool](./neg_pool.csv)\n",
    "    - [Neutral Pool](./neu_pool.csv)\n",
    "    \n",
    "### Procedure\n",
    "\n",
    "1. Start by initiializing the configuration variables\n",
    "    - `pos_file` = 'pos_pool.csv'\n",
    "    - `neg_file` = 'neg_pool.csv'\n",
    "    - `neu_file` = 'neu_pool.csv'\n",
    "    - `num_pools` = 3 \n",
    "    - `num_items_pure` = number of items in pure lists (must be evenly divisible by num_pools)\n",
    "    - `num_reps` =  number of repetitions of each block type\n",
    "    -  Verify the following (make sure number of mixed items is valid): \n",
    "        - `num_items_mixed = int(num_items_pure / num_pools)`\n",
    "        - `assert num_items_mixed * num_pools == num_items_pure`\n",
    "2. Load in the pools of data \n",
    "3. Shuffle the pools \n",
    "4. Define the `gen_block` function that creates a study/test block from the pools that are passed in:\n",
    "    - should take in `pools`, `cond`, and `num_items` as input\n",
    "    - should initialize an empty `study_list`\n",
    "    - should loop through the pools (being careful not to add duplicates) and look for `num_items` study items and add them to the study list; should update the study item's novelty and cond before adding to the `study_list`\n",
    "    - should shuffle the current state of the `study_list` after adding the elements\n",
    "    - should set `test_list` as a deep copy of `study_list`\n",
    "    - should loop over the pools again(being careful not to add duplicates) and look for `num_items` more test items and add them to the test list; should update the test item's novelty and cond before adding to the `test_list`\n",
    "    - should shuffle the current state of the `test_list` after adding the elements\n",
    "    - should return a dict containing `study_list` and `test_list`\n",
    "5. Generate the blocks \n",
    "    - create an empty list `blocks`\n",
    "    - loop through the `num_reps` and for each iteration:\n",
    "        - create a positive pure block using the `gen_block` function and using the appropriate parameters\n",
    "        - create a negative pure block using the `gen_block` function and using the appropriate parameters\n",
    "        - create a positive neutral block using the `gen_block` function and using the appropriate parameters\n",
    "        - create a mixed pos/neg/neu block using the `gen_block` function and using the appropriate parameters (be careful of the parameters here)\n",
    "6. Shuffle `blocks` and return \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "## SMILE Experiment Details\n",
    "\n",
    "### Objective\n",
    "Utilize the lists generated by code from the list generation method above to create an experiment for collecting data. For this Recognition Memory Test, participants will study a list of items one at a time, and then, after a short delay, be tested for their memory of those items. \n",
    "\n",
    "The main objectives of this experiment are the following:\n",
    "- Present an instruction screen to the participant that explains the tasks\n",
    "- Loop over the blocks of study--test lists. Each block has the following structure:\n",
    "    - Wait for the participant to press a key to start the block\n",
    "    - Loop over the study list presenting all the study items, one at a time; Each study item is presented like so:\n",
    "        - Present the item for a specified duration (this should be a configuration variable at the top of your code)\n",
    "        - Wait an inter-stimulus duration plus some amount of jitter (these, too, should be config variables)\n",
    "        - Log the stimulus information, including when it appeared on the screen\n",
    "    - Wait for a delay \n",
    "    - Loop over the test list presenting all the test items, one at a time; Each test item is presented like so:\n",
    "        - Present the item on the screen (with its Label) **until the participant makes a keyboard response of either the key you have selected to indicate the item is \"old\" or the key that indicates the item is \"new\"**\n",
    "        - Log the stimulus information, including when the stimulus appeared on the screen, when the participant made their response, and what response they made\n",
    "- Optional: Present an exit screen to the participant with a fun message!\n",
    "\n",
    "In the test phase of each block, participants will see the study items again, along with an equal number of new items, and for each item they must specify whether the item is an old target item (i.e., one that was on the study list) or a new lure item.\n",
    "\n",
    "\n",
    "\n",
    "### Requirements\n",
    "- Important packages to `import`\n",
    "    - `from smile.common import * `\n",
    "    - `from smile.scale import scale as s`\n",
    "    - `from smile.startup import InputSubject`\n",
    "\n",
    "\n",
    "### Procedure\n",
    "1. Start by initializing the configuration variables (including the listgen variables)\n",
    "    - Important variables include (replace empty or 0 variables with your desired configuration): \n",
    "        - `font_size = 0`\n",
    "        - `resp_keys = ['', '']` ***these are your keys to indicate if the item is \"old\" or if the item is \"new\"***\n",
    "        - `resp_map = {'': '', '': ''}`***this is used to associate the two keys chosen for `resp_keys` with \"old\" or \"new\"***\n",
    "        - `ISI_dur = 0`\n",
    "        - `ISI_jitter = 0` \n",
    "        - `LOC_X_jitter = 0`\n",
    "        - `LOC_Y_jitter = 0`\n",
    "        - `inst_font_size = 0 `\n",
    "        - `stim_time = 0`\n",
    "        - `inst_text = \"\"`\n",
    "        - `study_text = \"\"`\n",
    "        - `test_text = \"\"`\n",
    "        - `blocks` ***this should be created using the list_gen method above***\n",
    "2. Create your subroutines for `Instruct`, `Trial` and `Study`\n",
    "     - `Instruct` \n",
    "         - should use `inst_text` to render the instructions on the screen\n",
    "         - should wait for user input to continue\n",
    "     - `Trial` (This is an individual test item within the test list)\n",
    "         - should take in a `block_num`, `trial_num` and `cur_trial`\n",
    "         - should present the stimulus on the screen \n",
    "         - should wait for a response using the selected `resp_keys` from the participant (no timeout) \n",
    "         - should collect and log relevant data from the participant's response\n",
    "     - `Study` (This is an individual study item within the test list)\n",
    "         - should take in a `block_num`, `trial_num` and `cur_trial`\n",
    "         - should present the stimulus on the screen\n",
    "         - should wait the `ISI_dur` with `ISI_jitter`\n",
    "         - should log relevant data based on the stimulus\n",
    "3. Run Subroutines \n",
    "    1. Take subject id information using `InputSubject`\n",
    "    2. Use `Instruct` to present the instructions to the participant\n",
    "    3. `Wait` ***could use a configured amount or input 0.5 as default***\n",
    "    4. Loop over `blocks`; For each block:\n",
    "        1. Take user input to make sure they are ready to start the block\n",
    "        2. Present them with the `study_text` and wait for user input to make sure they are ready to begin the study portion of the block\n",
    "        3. Loop over the current block's study list using the `Study` subroutine\n",
    "        4. Wait the `ISI_dur` with `ISI_jitter`\n",
    "        5. Loop over the current block's study list using the `Trial` subroutine\n",
    "    4. Optional: Present an exit screen to the participant with a fun message!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Results\n",
    "\n",
    "## Primary Question: \n",
    "Is there an effect of valence (potentially interacting with condition) and correctness on response times?\n",
    "\n",
    "## Motivations \n",
    "Before running this analysis, I first want to introduce the motivations for this hypothesis. Thinking about the nature of the recognition memory test, there is some reason to believe that people process different words at diifferent rates. Particularly, positive, negative and neutral words may be percieved diffently based on one's personal experiences and could subsequently be processed differently. Additionally, there is reason to believe that incorrect responses had longer response times bcause the individual was potentially unsure of their response. \n",
    "\n",
    "Though causality can never be guaranteed in either of these cases, this analysis looks to see if there is some tangible effects in the data. From there, further analyses can be run to find more conclsive findings. \n",
    "\n",
    "## Important Variables\n",
    "Here the dependent variable will be `log_rt` instead of `rt` because ________. The independent variables will be `valence` and `correct`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data processing and visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ggplot: (7011879997)>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the right dataframe to plot and visualize the problem stated above\n",
    "# get the error corrected by condition and whether they answered correctly\n",
    "res = ci_within(df_w,  \n",
    "                indexvar='subj',       # column that identifies a subject\n",
    "                withinvars=['cond', 'correct', 'valence'],     # list of columns for grouping within subject\n",
    "                measvar='log_rt')        # dependent variable averaging over\n",
    "\n",
    "res = res.reset_index()\n",
    "\n",
    "p = (pn.ggplot(res, pn.aes('cond', 'mean', fill='valence'))\n",
    "     + pn.geom_errorbar(pn.aes(ymin='mean-ci', ymax='mean+ci', width=0.2), \n",
    "                        position=pn.position_dodge(.7))\n",
    "     + pn.geom_point(position=pn.position_dodge(.7), size=4)\n",
    "     + pn.facet_wrap('~ correct')\n",
    "     + pn.labs(title=\"Plot of log_rt by valence across correctness\", x=\"Condition\", y = \"P(log_rt)\", fill='Valence')\n",
    "    )\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In the figure above, we can see a plot of `log_rt` as a function of valence. The plot is split into correct and incorrect responses (labeled by the `1` and `0` at the top of each plot respectively). Furthermore, to account for differences in condition, two sets of plots (`mixed` and `pure`) were included for each valence and corectness. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Statistical test and interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subj</th>\n",
       "      <th>cond</th>\n",
       "      <th>valence</th>\n",
       "      <th>correct</th>\n",
       "      <th>log_rt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s001</td>\n",
       "      <td>mixed</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.167138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s001</td>\n",
       "      <td>mixed</td>\n",
       "      <td>neg</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.217212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s001</td>\n",
       "      <td>mixed</td>\n",
       "      <td>neu</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.109757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s001</td>\n",
       "      <td>mixed</td>\n",
       "      <td>neu</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.215241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s001</td>\n",
       "      <td>mixed</td>\n",
       "      <td>pos</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>s023</td>\n",
       "      <td>pure</td>\n",
       "      <td>neg</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.284881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>s023</td>\n",
       "      <td>pure</td>\n",
       "      <td>neu</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.249797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>s023</td>\n",
       "      <td>pure</td>\n",
       "      <td>neu</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.347838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>s023</td>\n",
       "      <td>pure</td>\n",
       "      <td>pos</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.357336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>s023</td>\n",
       "      <td>pure</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.447838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>276 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subj   cond valence  correct    log_rt\n",
       "0    s001  mixed     neg        0  0.167138\n",
       "1    s001  mixed     neg        1 -0.217212\n",
       "2    s001  mixed     neu        0 -0.109757\n",
       "3    s001  mixed     neu        1 -0.215241\n",
       "4    s001  mixed     pos        0  0.166381\n",
       "..    ...    ...     ...      ...       ...\n",
       "271  s023   pure     neg        1 -0.284881\n",
       "272  s023   pure     neu        0 -0.249797\n",
       "273  s023   pure     neu        1 -0.347838\n",
       "274  s023   pure     pos        0 -0.357336\n",
       "275  s023   pure     pos        1 -0.447838\n",
       "\n",
       "[276 rows x 5 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code for statistical test using statsmodel\n",
    "\n",
    "# use the agg method to get the means\n",
    "perf = df_w.groupby(['subj', 'cond', 'valence', 'correct'])['log_rt'].mean()\n",
    "perf = perf.reset_index()\n",
    "perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>log_rt</td>      <th>  R-squared:         </th> <td>   0.144</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   4.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 02 Dec 2020</td> <th>  Prob (F-statistic):</th> <td>1.70e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:59:04</td>     <th>  Log-Likelihood:    </th> <td> -52.458</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   276</td>      <th>  AIC:               </th> <td>   128.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   264</td>      <th>  BIC:               </th> <td>   172.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    11</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                   <td></td>                      <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                           <td>    0.0358</td> <td>    0.062</td> <td>    0.574</td> <td> 0.566</td> <td>   -0.087</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cond[T.pure]</th>                        <td>   -0.0377</td> <td>    0.088</td> <td>   -0.427</td> <td> 0.670</td> <td>   -0.211</td> <td>    0.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>valence[T.neu]</th>                      <td>   -0.0979</td> <td>    0.088</td> <td>   -1.110</td> <td> 0.268</td> <td>   -0.272</td> <td>    0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>valence[T.pos]</th>                      <td>    0.0480</td> <td>    0.088</td> <td>    0.544</td> <td> 0.587</td> <td>   -0.126</td> <td>    0.222</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cond[T.pure]:valence[T.neu]</th>         <td>    0.1971</td> <td>    0.125</td> <td>    1.580</td> <td> 0.115</td> <td>   -0.049</td> <td>    0.443</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cond[T.pure]:valence[T.pos]</th>         <td>   -0.0671</td> <td>    0.125</td> <td>   -0.538</td> <td> 0.591</td> <td>   -0.313</td> <td>    0.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>correct</th>                             <td>   -0.2348</td> <td>    0.088</td> <td>   -2.661</td> <td> 0.008</td> <td>   -0.409</td> <td>   -0.061</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cond[T.pure]:correct</th>                <td>    0.0233</td> <td>    0.125</td> <td>    0.186</td> <td> 0.852</td> <td>   -0.222</td> <td>    0.269</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>valence[T.neu]:correct</th>              <td>    0.0741</td> <td>    0.125</td> <td>    0.594</td> <td> 0.553</td> <td>   -0.172</td> <td>    0.320</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>valence[T.pos]:correct</th>              <td>   -0.0286</td> <td>    0.125</td> <td>   -0.229</td> <td> 0.819</td> <td>   -0.274</td> <td>    0.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cond[T.pure]:valence[T.neu]:correct</th> <td>   -0.1750</td> <td>    0.176</td> <td>   -0.992</td> <td> 0.322</td> <td>   -0.522</td> <td>    0.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cond[T.pure]:valence[T.pos]:correct</th> <td>    0.0680</td> <td>    0.176</td> <td>    0.385</td> <td> 0.700</td> <td>   -0.279</td> <td>    0.415</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>120.457</td> <th>  Durbin-Watson:     </th> <td>   0.866</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 535.822</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.794</td>  <th>  Prob(JB):          </th> <td>4.44e-117</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.807</td>  <th>  Cond. No.          </th> <td>    25.6</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 log_rt   R-squared:                       0.144\n",
       "Model:                            OLS   Adj. R-squared:                  0.109\n",
       "Method:                 Least Squares   F-statistic:                     4.053\n",
       "Date:                Wed, 02 Dec 2020   Prob (F-statistic):           1.70e-05\n",
       "Time:                        22:59:04   Log-Likelihood:                -52.458\n",
       "No. Observations:                 276   AIC:                             128.9\n",
       "Df Residuals:                     264   BIC:                             172.4\n",
       "Df Model:                          11                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=======================================================================================================\n",
       "                                          coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------------------\n",
       "Intercept                               0.0358      0.062      0.574      0.566      -0.087       0.159\n",
       "cond[T.pure]                           -0.0377      0.088     -0.427      0.670      -0.211       0.136\n",
       "valence[T.neu]                         -0.0979      0.088     -1.110      0.268      -0.272       0.076\n",
       "valence[T.pos]                          0.0480      0.088      0.544      0.587      -0.126       0.222\n",
       "cond[T.pure]:valence[T.neu]             0.1971      0.125      1.580      0.115      -0.049       0.443\n",
       "cond[T.pure]:valence[T.pos]            -0.0671      0.125     -0.538      0.591      -0.313       0.179\n",
       "correct                                -0.2348      0.088     -2.661      0.008      -0.409      -0.061\n",
       "cond[T.pure]:correct                    0.0233      0.125      0.186      0.852      -0.222       0.269\n",
       "valence[T.neu]:correct                  0.0741      0.125      0.594      0.553      -0.172       0.320\n",
       "valence[T.pos]:correct                 -0.0286      0.125     -0.229      0.819      -0.274       0.217\n",
       "cond[T.pure]:valence[T.neu]:correct    -0.1750      0.176     -0.992      0.322      -0.522       0.172\n",
       "cond[T.pure]:valence[T.pos]:correct     0.0680      0.176      0.385      0.700      -0.279       0.415\n",
       "==============================================================================\n",
       "Omnibus:                      120.457   Durbin-Watson:                   0.866\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              535.822\n",
       "Skew:                           1.794   Prob(JB):                    4.44e-117\n",
       "Kurtosis:                       8.807   Cond. No.                         25.6\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build a linear regression of the full model\n",
    "m0 = smf.ols(\"log_rt ~ cond * valence * correct\", perf).fit()\n",
    "m0.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Running an ANOVA on the linear model results\n",
    "\n",
    "- The results of such a complicated linear model is hard to unpack\n",
    "- The most common approach to modeling the data would be a repeated measures ANOVA\n",
    "- Luckily, a linear regress is really just an ANOVA if you make the right comparisons\n",
    "- To simplify the results of the regression, we will run an annova below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>df</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cond</th>\n",
       "      <td>0.000018</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>9.886632e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valence</th>\n",
       "      <td>0.026583</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.148474</td>\n",
       "      <td>8.620946e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cond:valence</th>\n",
       "      <td>0.256683</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.433668</td>\n",
       "      <td>2.402830e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>correct</th>\n",
       "      <td>3.519608</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.316559</td>\n",
       "      <td>1.463755e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cond:correct</th>\n",
       "      <td>0.002658</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.029688</td>\n",
       "      <td>8.633310e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valence:correct</th>\n",
       "      <td>0.004318</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.024119</td>\n",
       "      <td>9.761714e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cond:valence:correct</th>\n",
       "      <td>0.180761</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.009613</td>\n",
       "      <td>3.657622e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>23.633208</td>\n",
       "      <td>264.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         sum_sq     df          F        PR(>F)\n",
       "cond                   0.000018    1.0   0.000202  9.886632e-01\n",
       "valence                0.026583    2.0   0.148474  8.620946e-01\n",
       "cond:valence           0.256683    2.0   1.433668  2.402830e-01\n",
       "correct                3.519608    1.0  39.316559  1.463755e-09\n",
       "cond:correct           0.002658    1.0   0.029688  8.633310e-01\n",
       "valence:correct        0.004318    2.0   0.024119  9.761714e-01\n",
       "cond:valence:correct   0.180761    2.0   1.009613  3.657622e-01\n",
       "Residual              23.633208  264.0        NaN           NaN"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run a type-II repeated measures ANOVA based on the linear model results\n",
    "sm.stats.anova_lm(m0, typ=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Findings\n",
    "\n",
    "Looking at the results of the statistical analysis we can see that there is a big effect of corectness on response times. However there do not seem to be any other significant effects with valence and condition. This result seems fitting given the plots presented at the beginning of the analysis: big discrepancies in `log_rt` are obvious in incorrect vs correct plots. This is a very promising finding from our analysis, and with further study, more robust causal effects of correctness on response times may be found. \n",
    "\n",
    "Additionaly, it is worth noting that though there were no significant findings of valence effects on response times, in the plots above, there seemed to be some effect of positive and negative valence vs neutral valence on response times. That is to say that in the plots, positive and negative valences seemed to have slower response times when compared to neutral valences. Further analysis using a linear mixed effects regression will be needed to utilize `abs_valence` to see if this is a valid and significant effect. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Discussion\n",
    "\n",
    "***Graduate students only!!!***\n",
    "\n",
    "*In one to two paragraphs do the following: a) Place the study in the larger literature, summarizing some of the similar work in the field and how this study compares, b) write some analysis of the findings from the study (even if they are null results) and then describe a follow-up study with a new variant of the experiment that you think might help answer further questions on the topic."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "rise": {
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
