{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Assignment 8: D-Prime Plot\n",
    "## Computational Methods in Psychology (and Neuroscience)\n",
    "### Psychology 4500/7559 --- Fall 2020\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Objectives\n",
    "\n",
    "Upon completion of this assignment, students will have:\n",
    "\n",
    "1. Read in all the recognition memory data\n",
    "2. Performed some simple data clean-up (code provided)\n",
    "3. Calculated d-prime for the word recognition task\n",
    "4. Plotted d-prime as a function of valence and condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Assignment\n",
    "\n",
    "* Write code in a Jupyter notebook (after making a copy and renaming it to have your userid in the title --- e.g., A08_DPrime_Plot_mst3k).\n",
    "\n",
    "\n",
    "## Details\n",
    "\n",
    "Below is code that will load in the data from the two recognition memory experiments. As long as you have updated this repository from GitHub and unzipped the `all_data.zip` file in the `lessons` directory, the code should work unchanged to load in the data, create two data frames, and perform some minor clean-up of the data.\n",
    "\n",
    "Your task is to calculate d-prime for the word recognition data and then plot the result as a function of valence (negative, neutral, positive) and condition (mixed and pure).\n",
    "\n",
    "All the code you need to perform this analysis is in the most recent lesson notebook. You will need to identify the correct pieces of code to copy into this notebook and how to modify it to examine valence as opposed to image location. \n",
    "\n",
    "We have some code below to help you get started reading in the data, so that you can focus on the d-prime calculation and plot.\n",
    "\n",
    "* ***When you are done, save this notebook as HTML (`File -> Download as -> HTML`) and upload it to the matching assignment on UVACollab.***  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# New library to install\n",
    "\n",
    "You're going to need a new plotting library, so run this line at your Anaconda Prompt/Terminal:\n",
    "\n",
    "`conda install -c conda-forge plotnine` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## General Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some useful libraries\n",
    "import numpy as np                # numerical analysis linear algebra\n",
    "import pandas as pd               # efficient tables\n",
    "import matplotlib.pyplot as plt   # plotting\n",
    "import plotnine as pn \n",
    "import scipy.stats.distributions as dists     # probability distributions\n",
    "from scipy import stats\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "from smile.log import log2dl\n",
    "\n",
    "from ci_within import ci_within"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Custom SLOG loading function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom function to load slogs\n",
    "def load_all_subj_logs(task_dir, log_file):\n",
    "    # load in a list of all the subj\n",
    "    subjs = [os.path.split(subj_dir)[-1] \n",
    "             for subj_dir in glob(os.path.join(task_dir, 's*'))]\n",
    "    subjs.sort()\n",
    "\n",
    "    # loop over subj and their data\n",
    "    all_dat = []\n",
    "    for subj in subjs:\n",
    "        # set the file\n",
    "        log_path = os.path.join(task_dir, subj, log_file)\n",
    "        #print(log_path)\n",
    "\n",
    "        # load the data\n",
    "        all_dat.extend(log2dl(log_path, subj=subj))\n",
    "\n",
    "    df = pd.DataFrame(all_dat)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Load in all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resp_map_lure</th>\n",
       "      <th>resp_map_target</th>\n",
       "      <th>block_num</th>\n",
       "      <th>trial_num</th>\n",
       "      <th>stim_on_time</th>\n",
       "      <th>stim_on_error</th>\n",
       "      <th>resp</th>\n",
       "      <th>resp_time_time</th>\n",
       "      <th>resp_time_error</th>\n",
       "      <th>rt</th>\n",
       "      <th>...</th>\n",
       "      <th>valence_sd</th>\n",
       "      <th>arousal_mean</th>\n",
       "      <th>arousal_sd</th>\n",
       "      <th>dominance_mean</th>\n",
       "      <th>dominance_sd</th>\n",
       "      <th>word_frequency</th>\n",
       "      <th>novelty</th>\n",
       "      <th>cond</th>\n",
       "      <th>subj</th>\n",
       "      <th>log_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>234.395511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>J</td>\n",
       "      <td>235.284833</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.889323</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5700000000000001</td>\n",
       "      <td>5.3099999999999996</td>\n",
       "      <td>2.23</td>\n",
       "      <td>5.46</td>\n",
       "      <td>2.0499999999999998</td>\n",
       "      <td>3</td>\n",
       "      <td>target</td>\n",
       "      <td>neu</td>\n",
       "      <td>s001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>235.885654</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>237.034670</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>1.149016</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.1200000000000001</td>\n",
       "      <td>1.8300000000000001</td>\n",
       "      <td>5.6600000000000001</td>\n",
       "      <td>1.78</td>\n",
       "      <td>12</td>\n",
       "      <td>lure</td>\n",
       "      <td>neu</td>\n",
       "      <td>s001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>237.616869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>238.767406</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>1.150537</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8200000000000001</td>\n",
       "      <td>5.4500000000000002</td>\n",
       "      <td>2.1499999999999999</td>\n",
       "      <td>4.6399999999999997</td>\n",
       "      <td>2.0699999999999998</td>\n",
       "      <td>16</td>\n",
       "      <td>lure</td>\n",
       "      <td>neu</td>\n",
       "      <td>s001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>239.624933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>240.432295</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.807362</td>\n",
       "      <td>...</td>\n",
       "      <td>1.24</td>\n",
       "      <td>3.9500000000000002</td>\n",
       "      <td>2.5800000000000001</td>\n",
       "      <td>5.3700000000000001</td>\n",
       "      <td>1.6399999999999999</td>\n",
       "      <td>19</td>\n",
       "      <td>lure</td>\n",
       "      <td>neu</td>\n",
       "      <td>s001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>241.432209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>242.545227</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>1.113017</td>\n",
       "      <td>...</td>\n",
       "      <td>2.1600000000000001</td>\n",
       "      <td>3.6800000000000002</td>\n",
       "      <td>2.5699999999999998</td>\n",
       "      <td>5.8300000000000001</td>\n",
       "      <td>1.5</td>\n",
       "      <td>49</td>\n",
       "      <td>lure</td>\n",
       "      <td>neu</td>\n",
       "      <td>s001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  resp_map_lure resp_map_target  block_num  trial_num  stim_on_time  \\\n",
       "0             F               J          0          0    234.395511   \n",
       "1             F               J          0          1    235.885654   \n",
       "2             F               J          0          2    237.616869   \n",
       "3             F               J          0          3    239.624933   \n",
       "4             F               J          0          4    241.432209   \n",
       "\n",
       "   stim_on_error resp  resp_time_time  resp_time_error        rt  ...  \\\n",
       "0            0.0    J      235.284833         0.000180  0.889323  ...   \n",
       "1            0.0    F      237.034670         0.000182  1.149016  ...   \n",
       "2            0.0    F      238.767406         0.000238  1.150537  ...   \n",
       "3            0.0    F      240.432295         0.000182  0.807362  ...   \n",
       "4            0.0    F      242.545227         0.000192  1.113017  ...   \n",
       "\n",
       "           valence_sd        arousal_mean          arousal_sd  \\\n",
       "0  1.5700000000000001  5.3099999999999996                2.23   \n",
       "1                 1.5  4.1200000000000001  1.8300000000000001   \n",
       "2  1.8200000000000001  5.4500000000000002  2.1499999999999999   \n",
       "3                1.24  3.9500000000000002  2.5800000000000001   \n",
       "4  2.1600000000000001  3.6800000000000002  2.5699999999999998   \n",
       "\n",
       "       dominance_mean        dominance_sd word_frequency novelty cond  subj  \\\n",
       "0                5.46  2.0499999999999998              3  target  neu  s001   \n",
       "1  5.6600000000000001                1.78             12    lure  neu  s001   \n",
       "2  4.6399999999999997  2.0699999999999998             16    lure  neu  s001   \n",
       "3  5.3700000000000001  1.6399999999999999             19    lure  neu  s001   \n",
       "4  5.8300000000000001                 1.5             49    lure  neu  s001   \n",
       "\n",
       "  log_num  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data from the word recog task\n",
    "task_dir = os.path.join('..', 'lessons', 'data', 'Taskapalooza')\n",
    "\n",
    "df_w = load_all_subj_logs(task_dir, 'log_word_test')\n",
    "df_w.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Some data clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it turns out the cond is easier to visualize as pure and mixed\n",
    "def fix_conds(df, type_col):\n",
    "    # loop over the unique subjects\n",
    "    usubj = df.subj.unique()\n",
    "    for s in usubj:\n",
    "        # loop over their blocks\n",
    "        ublocks = df.loc[df['subj']==s, 'block_num'].unique()\n",
    "        for b in ublocks:\n",
    "            # grab the data for that subj and block\n",
    "            dfb = df.loc[(df['subj']==s)&(df['block_num']==b)]\n",
    "            \n",
    "            # get the unique types in that block\n",
    "            uval = dfb[type_col].unique()\n",
    "            if len(uval) > 1:\n",
    "                # it's mixed\n",
    "                df.loc[(df['subj']==s)&(df.block_num==b), 'cond'] = 'mixed'\n",
    "            else:\n",
    "                # it's the pure\n",
    "                df.loc[(df['subj']==s)&(df.block_num==b), 'cond'] = 'pure'\n",
    "\n",
    "# fix the conds in the recog experiments (updated in place)\n",
    "fix_conds(df_w, type_col='valence')\n",
    "\n",
    "\n",
    "# add in log_rt columns\n",
    "df_w['log_rt'] = np.log(df_w['rt'])\n",
    "\n",
    "# must make correct an int\n",
    "df_w['correct'] = df_w['correct'].astype(np.int)\n",
    "\n",
    "# add in a column for whether they made an 'old' response\n",
    "df_w['old_resp'] = (df_w['resp_map_target'] == df_w['resp']).astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating sensitivity\n",
    "\n",
    "- Under assumptions of equal variance for both the signal and noise distributions, the d' (d-prime) is the measure of sensitivity\n",
    "\n",
    "$$d' = ((\\mu + \\alpha) - \\mu) / \\sigma$$\n",
    "$$d' = \\alpha / \\sigma$$\n",
    "\n",
    "- Thus, $d'$ is the difference between the two distributions in units of the standard deviation\n",
    "- Note, this is independent of the criterion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dprime(n_hits, n_targets, n_false_alarms, n_lures):\n",
    "    # calculate corrected hit rate and false alarm rate (to avoid zeros)\n",
    "    hr_trans = (n_hits+.5)/(n_targets+1)\n",
    "    far_trans = (n_false_alarms+.5)/(n_lures+1)\n",
    "    \n",
    "    # calculate dprime\n",
    "    Z = dists.norm.ppf\n",
    "    dprime = Z(hr_trans) - Z(far_trans)\n",
    "    return dprime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your code goes below here\n",
    "\n",
    "All code above should work without modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the agg method to get the counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collapse the multi-index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use apply to add the dprime as a new column (axis=1 tells it to go by row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use ci_within to calcuate the mean and confidence interval of d-prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use plotnine to plot dprime as a function of condition, with a fill-color defined by valence\n",
    "# be sure to label your axes correctly and add the confidence interval with error bars"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "rise": {
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
