{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4: List Generation for Experiments\n",
    "## Computational Methods in Psychology (and Neuroscience)\n",
    "### Psychology 4500/7559 --- Fall 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "\n",
    "Upon completion of this assignment, the student will have:\n",
    "\n",
    "1. Read in a stimulus pool from a file.\n",
    "\n",
    "2. Randomly generated lists to use in a experiment.\n",
    "\n",
    "3. Written the lists out to files for future use.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "* Write code in a Jupyter notebook (after making a copy and renaming it to have your userid in the title --- e.g., A04_ListGen_mst3k).\n",
    "\n",
    "## Design\n",
    "\n",
    "Your assignment is to write a script that reads in a pool of stimuli\n",
    "and creates lists of dictionaries that you will later present to\n",
    "participants as part of an experiment.  \n",
    "\n",
    "The script should be configurable such that you can specify different\n",
    "numbers of lists and trials, along with other details specific to the\n",
    "experiment you decide to do.\n",
    "\n",
    "Each dictionary represents a trial and should contain all the\n",
    "information necessary to identify the stimulus to be presented,\n",
    "details about that stimulus, and the condition in which to present it.\n",
    "This information will be experiment-specific, as outlined below.\n",
    "\n",
    "You have three options for your experiment.  Please select **one** of\n",
    "the following experiments, keeping in mind that your next assignment\n",
    "will be to code the experiment presentation and response collection\n",
    "for the lists you generate from this assignment.\n",
    "\n",
    "  \n",
    "* ***When you are done, save this notebook as HTML (`File -> Download as -> HTML`) and upload it to the matching assignment on UVACollab.***  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: Valence Study\n",
    "\n",
    "The main question of this study is whether recognition memory for\n",
    "words depends on the emotional or affective valence of those words.\n",
    "Participants will study lists of positive (+), negative (-), and\n",
    "neutral (~) words and then, after a short delay, they will be given a\n",
    "recognition test over all the studied target words plus a matched set\n",
    "of non-studied lures.  The stimuli are contained in three separate CSV\n",
    "files:\n",
    "\n",
    "- [Positive Pool](./pos_pool.csv)\n",
    "- [Negative Pool](./neg_pool.csv)\n",
    "- [Neutral Pool](./neu_pool.csv)\n",
    "\n",
    "You will need to read these files in as lists of dictionaries (hint,\n",
    "use the ``DictReader`` from the ``csv`` module that was covered in\n",
    "class.)  Use these pools to create lists of trials for two\n",
    "experimental conditions: pure or mixed.  In the *pure* condition,\n",
    "all of the trials should be words from the same valence (be sure to\n",
    "have the same number of positive, negative, and neutral pure lists.)\n",
    "In the *mixed* condition, each list should contain an equal number of\n",
    "positive, negative, and neutral words in *random* order (hint, use the\n",
    "``shuffle`` function provided by the ``random`` module.) \n",
    "\n",
    "You will need to generate a matching test list for each study list\n",
    "that includes all the studied items, plus a set of lures that match\n",
    "the valence of the studied words.\n",
    "\n",
    "Be sure to add in information to each trial dictionary that identifies\n",
    "the word, its valence, the condition of the list, and whether it is a\n",
    "target or a lure.  Feel free to add in more information if you would\n",
    "like.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "\n",
    "pos_pool = csv.DictReader(open('pos_pool.csv', 'r'))\n",
    "neg_pool = csv.DictReader(open('neg_pool.csv', 'r'))\n",
    "neu_pool = csv.DictReader(open('neu_pool.csv', 'r'))\n",
    "pos_list=[]\n",
    "for l in pos_pool:\n",
    "    x = {}\n",
    "    x['stimulus'] = l['description']\n",
    "    x['valence'] = 'POS'\n",
    "    pos_list.append(x)\n",
    "neg_list =[]\n",
    "for l in neg_pool:\n",
    "    x = {}\n",
    "    x['stimulus'] = l['description']\n",
    "    x['valence'] = 'NEG'\n",
    "    neg_list.append(x)\n",
    "neu_list=[]\n",
    "for l in neu_pool:\n",
    "    x = {}\n",
    "    x['stimulus'] = l['description']\n",
    "    x['valence'] = 'NEU'\n",
    "    neu_list.append(x)\n",
    "    \n",
    "random.shuffle(pos_list)\n",
    "random.shuffle(neg_list)\n",
    "random.shuffle(neu_list)\n",
    "\n",
    "def gen_pure(num_study, pool_list):\n",
    "    pure_study = []\n",
    "    pure_test = []\n",
    "    pure = {} \n",
    "    for i in range(num_study):\n",
    "        l_dict = pool_list[int(i + ((num_study/3)* 2))]\n",
    "        x = {}\n",
    "        x['stimulus'] = l_dict['stimulus']\n",
    "        x['valence'] = l_dict['valence']\n",
    "        x['cond'] = 'PURE'\n",
    "        x['novelty'] = 'TARGET'\n",
    "        pure_test.append(x)\n",
    "        pure_study.append(x)\n",
    "    for j in range(num_study):\n",
    "        l_dict = pool_list[int(j + ((num_study/3)* 2) + num_study)]\n",
    "        x = {}\n",
    "        x['stimulus'] = l_dict['stimulus']\n",
    "        x['valence'] = l_dict['valence']\n",
    "        x['cond'] = 'PURE'\n",
    "        x['novelty'] = 'LURE'\n",
    "        pure_test.append(x)\n",
    "    random.shuffle(pure_test)\n",
    "    pure['study_list'] = pure_study\n",
    "    pure['test_list'] = pure_test\n",
    "    return pure\n",
    "\n",
    "def gen_mixed(num_study):\n",
    "    mix_study = []\n",
    "    mix_test = []\n",
    "    mix = {}\n",
    "    for i in range(num_study):\n",
    "        pos_dict = pos_list[i]\n",
    "        x = {}\n",
    "        x['stimulus'] = pos_dict['stimulus']\n",
    "        x['valence'] = pos_dict['valence']\n",
    "        x['cond'] = 'MIXED'\n",
    "        x['novelty'] = 'TARGET'\n",
    "        mix_test.append(x)\n",
    "        mix_study.append(x)\n",
    "        neg_dict = neg_list[i]\n",
    "        y = {}\n",
    "        y['stimulus'] = neg_dict['stimulus']\n",
    "        y['valence'] = neg_dict['valence']\n",
    "        y['cond'] = 'MIXED'\n",
    "        y['novelty'] = 'TARGET'\n",
    "        mix_test.append(y)\n",
    "        mix_study.append(y)\n",
    "        neu_dict = neu_list[i]\n",
    "        z = {}\n",
    "        z['stimulus'] = neu_dict['stimulus']\n",
    "        z['valence'] = neu_dict['valence']\n",
    "        z['cond'] = 'PURE'\n",
    "        z['novelty'] = 'TARGET'\n",
    "        mix_test.append(z)\n",
    "        mix_study.append(z)\n",
    "    for j in range(num_study):\n",
    "        pos_dict = pos_list[j+num_study]\n",
    "        x = {}\n",
    "        x['stimulus'] = pos_dict['stimulus']\n",
    "        x['valence'] = pos_dict['valence']\n",
    "        x['cond'] = 'MIXED'\n",
    "        x['novelty'] = 'LURE'\n",
    "        mix_test.append(x)\n",
    "        neg_dict = neg_list[j+num_study]\n",
    "        y = {}\n",
    "        y['stimulus'] = neg_dict['stimulus']\n",
    "        y['valence'] = neg_dict['valence']\n",
    "        y['cond'] = 'MIXED'\n",
    "        y['novelty'] = 'LURE'\n",
    "        mix_test.append(y)\n",
    "        neu_dict = neu_list[j+num_study]\n",
    "        z = {}\n",
    "        z['stimulus'] = neu_dict['stimulus']\n",
    "        z['valence'] = neu_dict['valence']\n",
    "        z['cond'] = 'PURE'\n",
    "        z['novelty'] = 'LURE'\n",
    "    random.shuffle(mix_test)\n",
    "    mix['study_list'] = mix_study\n",
    "    mix['test_list'] = mix_test\n",
    "    mix_test.append(z)\n",
    "    return mix\n",
    "\n",
    "def gen_blocks(num_blocks, num_study):\n",
    "    blocks = []\n",
    "    for i in range(num_blocks):\n",
    "        mixed = gen_mixed(num_study)\n",
    "        pos_pure = gen_pure(num_study*3,pos_list)\n",
    "        neg_pure = gen_pure(num_study*3,neg_list)\n",
    "        neu_pure = gen_pure(num_study*3,neu_list)\n",
    "        random.shuffle(pos_list)\n",
    "        random.shuffle(neg_list)\n",
    "        random.shuffle(neu_list)\n",
    "        blocks.append(pos_pure)\n",
    "        blocks.append(neg_pure)\n",
    "        blocks.append(neu_pure)\n",
    "        blocks.append(mixed)\n",
    "    return blocks\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many blocks would you like for the study? 2\n",
      "How many items would you like for EACH valance in the mixed study list? 1\n",
      "PLEASE NOTE: You will have 3 items for EACH study list and 6 items for EACH test list\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'study_list': [{'stimulus': 'graduate',\n",
       "    'valence': 'POS',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'TARGET'},\n",
       "   {'stimulus': 'river',\n",
       "    'valence': 'POS',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'TARGET'},\n",
       "   {'stimulus': 'soothe',\n",
       "    'valence': 'POS',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'TARGET'}],\n",
       "  'test_list': [{'stimulus': 'soothe',\n",
       "    'valence': 'POS',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'TARGET'},\n",
       "   {'stimulus': 'people', 'valence': 'POS', 'cond': 'PURE', 'novelty': 'LURE'},\n",
       "   {'stimulus': 'crown', 'valence': 'POS', 'cond': 'PURE', 'novelty': 'LURE'},\n",
       "   {'stimulus': 'river',\n",
       "    'valence': 'POS',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'TARGET'},\n",
       "   {'stimulus': 'diploma',\n",
       "    'valence': 'POS',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'LURE'},\n",
       "   {'stimulus': 'graduate',\n",
       "    'valence': 'POS',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'TARGET'}]},\n",
       " {'study_list': [{'stimulus': 'dagger',\n",
       "    'valence': 'NEG',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'TARGET'},\n",
       "   {'stimulus': 'unhappy',\n",
       "    'valence': 'NEG',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'TARGET'},\n",
       "   {'stimulus': 'scandal',\n",
       "    'valence': 'NEG',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'TARGET'}],\n",
       "  'test_list': [{'stimulus': 'headache',\n",
       "    'valence': 'NEG',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'LURE'},\n",
       "   {'stimulus': 'beggar', 'valence': 'NEG', 'cond': 'PURE', 'novelty': 'LURE'},\n",
       "   {'stimulus': 'dagger',\n",
       "    'valence': 'NEG',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'TARGET'},\n",
       "   {'stimulus': 'scandal',\n",
       "    'valence': 'NEG',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'TARGET'},\n",
       "   {'stimulus': 'dentist',\n",
       "    'valence': 'NEG',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'LURE'},\n",
       "   {'stimulus': 'unhappy',\n",
       "    'valence': 'NEG',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'TARGET'}]},\n",
       " {'study_list': [{'stimulus': 'limber',\n",
       "    'valence': 'NEU',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'TARGET'},\n",
       "   {'stimulus': 'reserved',\n",
       "    'valence': 'NEU',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'TARGET'},\n",
       "   {'stimulus': 'tool',\n",
       "    'valence': 'NEU',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'TARGET'}],\n",
       "  'test_list': [{'stimulus': 'tool',\n",
       "    'valence': 'NEU',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'TARGET'},\n",
       "   {'stimulus': 'chair', 'valence': 'NEU', 'cond': 'PURE', 'novelty': 'LURE'},\n",
       "   {'stimulus': 'reserved',\n",
       "    'valence': 'NEU',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'TARGET'},\n",
       "   {'stimulus': 'limber',\n",
       "    'valence': 'NEU',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'TARGET'},\n",
       "   {'stimulus': 'office', 'valence': 'NEU', 'cond': 'PURE', 'novelty': 'LURE'},\n",
       "   {'stimulus': 'pamphlet',\n",
       "    'valence': 'NEU',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'LURE'}]},\n",
       " {'study_list': [{'stimulus': 'intellect',\n",
       "    'valence': 'POS',\n",
       "    'cond': 'MIXED',\n",
       "    'novelty': 'TARGET'},\n",
       "   {'stimulus': 'obnoxious',\n",
       "    'valence': 'NEG',\n",
       "    'cond': 'MIXED',\n",
       "    'novelty': 'TARGET'},\n",
       "   {'stimulus': 'wagon',\n",
       "    'valence': 'NEU',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'TARGET'}],\n",
       "  'test_list': [{'stimulus': 'wagon',\n",
       "    'valence': 'NEU',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'TARGET'},\n",
       "   {'stimulus': 'food', 'valence': 'POS', 'cond': 'MIXED', 'novelty': 'LURE'},\n",
       "   {'stimulus': 'intellect',\n",
       "    'valence': 'POS',\n",
       "    'cond': 'MIXED',\n",
       "    'novelty': 'TARGET'},\n",
       "   {'stimulus': 'obnoxious',\n",
       "    'valence': 'NEG',\n",
       "    'cond': 'MIXED',\n",
       "    'novelty': 'TARGET'},\n",
       "   {'stimulus': 'shamed',\n",
       "    'valence': 'NEG',\n",
       "    'cond': 'MIXED',\n",
       "    'novelty': 'LURE'},\n",
       "   {'stimulus': 'jelly',\n",
       "    'valence': 'NEU',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'LURE'}]},\n",
       " {'study_list': [{'stimulus': 'tender',\n",
       "    'valence': 'POS',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'TARGET'},\n",
       "   {'stimulus': 'protected',\n",
       "    'valence': 'POS',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'TARGET'},\n",
       "   {'stimulus': 'talent',\n",
       "    'valence': 'POS',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'TARGET'}],\n",
       "  'test_list': [{'stimulus': 'tender',\n",
       "    'valence': 'POS',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'TARGET'},\n",
       "   {'stimulus': 'talent',\n",
       "    'valence': 'POS',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'TARGET'},\n",
       "   {'stimulus': 'diamond',\n",
       "    'valence': 'POS',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'LURE'},\n",
       "   {'stimulus': 'kind', 'valence': 'POS', 'cond': 'PURE', 'novelty': 'LURE'},\n",
       "   {'stimulus': 'soothe', 'valence': 'POS', 'cond': 'PURE', 'novelty': 'LURE'},\n",
       "   {'stimulus': 'protected',\n",
       "    'valence': 'POS',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'TARGET'}]},\n",
       " {'study_list': [{'stimulus': 'rusty',\n",
       "    'valence': 'NEG',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'TARGET'},\n",
       "   {'stimulus': 'fearful',\n",
       "    'valence': 'NEG',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'TARGET'},\n",
       "   {'stimulus': 'wicked',\n",
       "    'valence': 'NEG',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'TARGET'}],\n",
       "  'test_list': [{'stimulus': 'mangle',\n",
       "    'valence': 'NEG',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'LURE'},\n",
       "   {'stimulus': 'crushed',\n",
       "    'valence': 'NEG',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'LURE'},\n",
       "   {'stimulus': 'rusty',\n",
       "    'valence': 'NEG',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'TARGET'},\n",
       "   {'stimulus': 'fearful',\n",
       "    'valence': 'NEG',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'TARGET'},\n",
       "   {'stimulus': 'wicked',\n",
       "    'valence': 'NEG',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'TARGET'},\n",
       "   {'stimulus': 'stench',\n",
       "    'valence': 'NEG',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'LURE'}]},\n",
       " {'study_list': [{'stimulus': 'indifferent',\n",
       "    'valence': 'NEU',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'TARGET'},\n",
       "   {'stimulus': 'lesbian',\n",
       "    'valence': 'NEU',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'TARGET'},\n",
       "   {'stimulus': 'cat', 'valence': 'NEU', 'cond': 'PURE', 'novelty': 'TARGET'}],\n",
       "  'test_list': [{'stimulus': 'indifferent',\n",
       "    'valence': 'NEU',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'TARGET'},\n",
       "   {'stimulus': 'lightbulb',\n",
       "    'valence': 'NEU',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'LURE'},\n",
       "   {'stimulus': 'cat', 'valence': 'NEU', 'cond': 'PURE', 'novelty': 'TARGET'},\n",
       "   {'stimulus': 'highway',\n",
       "    'valence': 'NEU',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'LURE'},\n",
       "   {'stimulus': 'lesbian',\n",
       "    'valence': 'NEU',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'TARGET'},\n",
       "   {'stimulus': 'cannon',\n",
       "    'valence': 'NEU',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'LURE'}]},\n",
       " {'study_list': [{'stimulus': 'flower',\n",
       "    'valence': 'POS',\n",
       "    'cond': 'MIXED',\n",
       "    'novelty': 'TARGET'},\n",
       "   {'stimulus': 'grenade',\n",
       "    'valence': 'NEG',\n",
       "    'cond': 'MIXED',\n",
       "    'novelty': 'TARGET'},\n",
       "   {'stimulus': 'vest',\n",
       "    'valence': 'NEU',\n",
       "    'cond': 'PURE',\n",
       "    'novelty': 'TARGET'}],\n",
       "  'test_list': [{'stimulus': 'fungus',\n",
       "    'valence': 'NEG',\n",
       "    'cond': 'MIXED',\n",
       "    'novelty': 'LURE'},\n",
       "   {'stimulus': 'grenade',\n",
       "    'valence': 'NEG',\n",
       "    'cond': 'MIXED',\n",
       "    'novelty': 'TARGET'},\n",
       "   {'stimulus': 'profit',\n",
       "    'valence': 'POS',\n",
       "    'cond': 'MIXED',\n",
       "    'novelty': 'LURE'},\n",
       "   {'stimulus': 'vest', 'valence': 'NEU', 'cond': 'PURE', 'novelty': 'TARGET'},\n",
       "   {'stimulus': 'flower',\n",
       "    'valence': 'POS',\n",
       "    'cond': 'MIXED',\n",
       "    'novelty': 'TARGET'},\n",
       "   {'stimulus': 'jug', 'valence': 'NEU', 'cond': 'PURE', 'novelty': 'LURE'}]}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_blocks = (int(input(\"How many blocks would you like for the study? \")))\n",
    "num_study = (int(input(\"How many items would you like for EACH valance in the mixed study list? \")))\n",
    "print(\"PLEASE NOTE: You will have \" + str(num_study * 3) + \" items for EACH study list and \" + str(num_study * 6)  + \" items for EACH test list\")\n",
    "\n",
    "# max number of items for num_study input is 26\n",
    "# because the neutral pool has the least number of items which is 209 items\n",
    "# the mixed test list would have 26 x 2 neutral test items (26 lures and 26 targets) items = 52\n",
    "# using the same logic, the neutral pure test list would have ((26 x 3) x 2) items = 156\n",
    "# 156 + 52 = 208... any more and we would go out of bounds \n",
    "assert (num_study < 27), \"TOO MANY ITEMS. Please pick a smaller number of study items\"\n",
    "\n",
    "gen_blocks(num_blocks,num_study)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: Scene Study\n",
    "\n",
    "This study will test whether recognition memory for indoor and outdoor\n",
    "scenes is modulated by the structure of the study lists.\n",
    "Specifically, participants will study lists that either have indoor\n",
    "and outdoor scenes that come in pure blocks or intermixed (similar to\n",
    "the Valence study above).  The participants will then be given a\n",
    "recognition test over all the studied target images plus a matched set\n",
    "of non-studied lures.  You can access the lists of stimuli available:\n",
    "\n",
    "- [Indoor Pool](./indoor.csv)\n",
    "- [Outdoor Pool](./outdoor.csv)\n",
    "\n",
    "You will need to read these files in as lists of dictionaries (hint,\n",
    "use the ``DictReader`` from the ``csv`` module that was covered in\n",
    "class.)  For the actual experiment we will give you the images that\n",
    "are referenced by the file names in these pools, but for the list\n",
    "generation you do not need the images, themselves and should identify\n",
    "the image you will be presenting using the file name.  Use these pools\n",
    "to create lists of trials for two experimental conditions: pure or\n",
    "mixed.  In the *pure* condition, all of the trials should be images\n",
    "from the same category (be sure to have the same number of indoor\n",
    "and outdoor pure lists.)  In the *mixed* condition, each\n",
    "list should contain an equal number of indoor and outdoor\n",
    "images in *random* order (hint, use the ``shuffle`` function provided\n",
    "by the ``random`` module.)\n",
    "\n",
    "You will need to generate a matching test list for each study list\n",
    "that includes all the studied items, plus a set of lures that match\n",
    "the image categories from the studied items.\n",
    "\n",
    "Be sure to add in information to each trial dictionary that identifies\n",
    "the file name, the category of the image, the condition of the list,\n",
    "and whether it is a target or a lure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 3: Your own study\n",
    "\n",
    "You may also generate lists for a study specifically relevant to your\n",
    "own work.  We are extremely supportive of this, but the study must be\n",
    "approved by the professor.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
